{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FRIENDS_ELECTRA_지원의 사본","provenance":[{"file_id":"17xPP47ZcisQuvyWC-dbZAKuykYv5cyCw","timestamp":1592196614463},{"file_id":"1qMmtjmDtYFAudWZgN-vwzu3inilrkiBp","timestamp":1591982370104}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f337806c3b044cffbb783829dd6e67c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_337df8151f354da080d8e14714fcb755","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ade91b65bbbf4432afc44cd110474510","IPY_MODEL_02b3f30d2e224cd1b05e9ff93d56954b"]}},"337df8151f354da080d8e14714fcb755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ade91b65bbbf4432afc44cd110474510":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_debe6a088a3f44b7a7e0063711f11b10","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9518b8e436b04dc9892f86c3c0c74468"}},"02b3f30d2e224cd1b05e9ff93d56954b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cac37ab0e9644250a4d5cbaa15ece1e1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 2.62MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42c050449d8842af8b44a2d6b87e7a11"}},"debe6a088a3f44b7a7e0063711f11b10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9518b8e436b04dc9892f86c3c0c74468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cac37ab0e9644250a4d5cbaa15ece1e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"42c050449d8842af8b44a2d6b87e7a11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b29d7158df5c4b4b863af9b5ccb2c4da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5cac92b76595431586bc2b8d6b3e7db1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_abe43b0426224fca9715b7b3f76477b9","IPY_MODEL_114d3ae1c64c4f84a191ed94063abb01"]}},"5cac92b76595431586bc2b8d6b3e7db1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"abe43b0426224fca9715b7b3f76477b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4359c1195de541559fb33812aa2bcfbf","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":463,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":463,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1d0e920d6cf4bdebe97e23523c5850e"}},"114d3ae1c64c4f84a191ed94063abb01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9c0c907ab5604086803e0b95cbcd4dab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 463/463 [00:02&lt;00:00, 215B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25a12769132140de9428badc5ec39f20"}},"4359c1195de541559fb33812aa2bcfbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1d0e920d6cf4bdebe97e23523c5850e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c0c907ab5604086803e0b95cbcd4dab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"25a12769132140de9428badc5ec39f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8a9d59d48e84d7996b8d720f4aaef30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e816b310126416aaad98a8da185c8da","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1407c94b0ac44f5e93473ee46c994307","IPY_MODEL_8ebcf6c8d1524a0bae821b43c6cb5d66"]}},"4e816b310126416aaad98a8da185c8da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1407c94b0ac44f5e93473ee46c994307":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_49b659a2a1bf4c419d5505d1304900fb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":54236116,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":54236116,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9659dcb541fa4942a1f4c12110bc6529"}},"8ebcf6c8d1524a0bae821b43c6cb5d66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d421f38ebf7d462e8e60072deddfd5a8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 54.2M/54.2M [00:01&lt;00:00, 43.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a124a52176264facad1715b974c8df9c"}},"49b659a2a1bf4c419d5505d1304900fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9659dcb541fa4942a1f4c12110bc6529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d421f38ebf7d462e8e60072deddfd5a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a124a52176264facad1715b974c8df9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"gP2MkKlZo92B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1593150436131,"user_tz":-540,"elapsed":2593,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"c1306b85-3d70-4258-816b-5b8c55dd621a"},"source":["!unzip Friends.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  Friends.zip\n","  inflating: friends_dev.json        \n","  inflating: __MACOSX/._friends_dev.json  \n","  inflating: friends_test.json       \n","  inflating: __MACOSX/._friends_test.json  \n","  inflating: friends_train.json      \n","  inflating: __MACOSX/._friends_train.json  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6L4cQQhK5Ct0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1593150444156,"user_tz":-540,"elapsed":7335,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"8e529583-4279-408d-9623-61838b30c8a7"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 10.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 41.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 43.6MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=79eefcf97a50f920d56042f426ff1b603d390d12416e12887a13b0c5c9fc0ffc\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ruNN11LG5X4u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593150453772,"user_tz":-540,"elapsed":5450,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"639a2502-19fc-494f-d84d-c1280c7d287f"},"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import ElectraTokenizer, ElectraForSequenceClassification\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import json\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"A-0roV-569a3","colab_type":"code","colab":{}},"source":["def jsonToDf(file_name):\n","  with open(file_name, encoding = 'utf-8', mode = 'r') as file:\n","    json_array = json.load(file)\n","  \n","  result = pd.DataFrame.from_dict(json_array[0])\n","\n","  is_first = True\n","  for array in json_array:\n","    if is_first:\n","      is_first = False\n","      continue\n","    \n","    temp_df = pd.DataFrame.from_dict(array)\n","    result = result.append(temp_df, ignore_index = True)\n","\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6egFjJ48qzG","colab_type":"code","colab":{}},"source":["train = jsonToDf('friends_train.json')\n","dev = jsonToDf('friends_dev.json')\n","train2 = jsonToDf('friends_test.json')\n","\n","train = train.append(train2, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"__JORU-clz0l","colab_type":"code","colab":{}},"source":["test = pd.read_csv('en_data.csv', encoding = 'unicode_escape')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iInrB1bgnGy-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593150464321,"user_tz":-540,"elapsed":889,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"1da4c405-5361-487a-fc2e-3891b32f3944"},"source":["test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>i_dialog</th>\n","      <th>i_utterance</th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Phoebe</td>\n","      <td>Alright, whadyou do with him?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Monica</td>\n","      <td>Oh! You're awake!</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Joey</td>\n","      <td>Then you gotta come clean with Ma! This is not...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Mr. Tribbiani</td>\n","      <td>Yeah, but this is</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Joey</td>\n","      <td>I don't wanna hear it! Now go to my room!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          utterance\n","0   0  ...                      Alright, whadyou do with him?\n","1   1  ...                                  Oh! You're awake!\n","2   2  ...  Then you gotta come clean with Ma! This is not...\n","3   3  ...                                  Yeah, but this is\n","4   4  ...          I don't wanna hear it! Now go to my room!\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"lmliMLzI85i6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593150466525,"user_tz":-540,"elapsed":726,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"e71e13d0-5deb-40f7-cbcd-74603ee1929f"},"source":["print(train.shape)\n","print(dev.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(13325, 4)\n","(1178, 4)\n","(3296, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pmyUQewC7Hn0","colab_type":"code","colab":{}},"source":["MAX_LEN = 85\n","\n","def getInputsAndLabels(dataset):\n","  data = dataset.copy(deep=True)\n","  #data['utterance'] = data['utterance'].str.lower()\n","\n","  utterances = data['utterance']\n","  utterances = [\"[CLS] \" + str(utterance) + \" [SEP]\" for utterance in utterances]\n","  \n","  encoder = LabelEncoder()\n","  labels = data['emotion'].values\n","  encoder.fit(labels)\n","  labels = encoder.transform(labels)\n","\n","  tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n","\n","  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","  attention_masks = []\n","  for seq in input_ids:\n","      seq_mask = [float(i>0) for i in seq]\n","      attention_masks.append(seq_mask)\n","\n","  return input_ids, labels, attention_masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EVlb_5RnptP","colab_type":"code","colab":{}},"source":["def getInputsFromTest(dataset):\n","  data = dataset.copy(deep=True)\n","  #data['utterance'] = data['utterance'].str.lower()\n","\n","  utterances = data['utterance']\n","  utterances = [\"[CLS] \" + str(utterance) + \" [SEP]\" for utterance in utterances]\n","  \n","  tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n","\n","  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","  attention_masks = []\n","  for seq in input_ids:\n","      seq_mask = [float(i>0) for i in seq]\n","      attention_masks.append(seq_mask)\n","\n","  return input_ids, attention_masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MnirJQxrERms","colab_type":"code","colab":{}},"source":["def getIndex(dataset):\n","  data = dataset.copy(deep = True)\n","  input_index = data.id.tolist()\n","  return torch.tensor(input_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lwNgpRzc7lIv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["f337806c3b044cffbb783829dd6e67c7","337df8151f354da080d8e14714fcb755","ade91b65bbbf4432afc44cd110474510","02b3f30d2e224cd1b05e9ff93d56954b","debe6a088a3f44b7a7e0063711f11b10","9518b8e436b04dc9892f86c3c0c74468","cac37ab0e9644250a4d5cbaa15ece1e1","42c050449d8842af8b44a2d6b87e7a11"]},"executionInfo":{"status":"ok","timestamp":1593150483278,"user_tz":-540,"elapsed":5353,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"0b26adcb-d1fc-47e8-ca9c-226be8099891"},"source":["train_inputs, train_labels, train_masks = getInputsAndLabels(train)\n","dev_inputs, dev_labels, dev_masks = getInputsAndLabels(dev)\n","test_inputs, test_masks = getInputsFromTest(test)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f337806c3b044cffbb783829dd6e67c7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i0jKFX9b_RMo","colab_type":"code","colab":{}},"source":["train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","\n","dev_inputs = torch.tensor(dev_inputs)\n","dev_labels = torch.tensor(dev_labels)\n","dev_masks = torch.tensor(dev_masks)\n","\n","test_index = getIndex(test)\n","test_inputs = torch.tensor(test_inputs)\n","test_masks = torch.tensor(test_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zl6EOni__5M","colab_type":"code","colab":{}},"source":["batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","dev_data = TensorDataset(dev_inputs, dev_masks, dev_labels)\n","dev_sampler = SequentialSampler(dev_data)\n","dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)\n","\n","test_data = TensorDataset(test_index, test_inputs, test_masks)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AO2EtdExAmiG","colab_type":"text"},"source":["## **모델 구현**"]},{"cell_type":"code","metadata":{"id":"EN-mJst1Fn7x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593150492947,"user_tz":-540,"elapsed":638,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"aeca4dad-dcdf-4479-8921-c04e2469c8db"},"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xC8tp9PUAlAK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b29d7158df5c4b4b863af9b5ccb2c4da","5cac92b76595431586bc2b8d6b3e7db1","abe43b0426224fca9715b7b3f76477b9","114d3ae1c64c4f84a191ed94063abb01","4359c1195de541559fb33812aa2bcfbf","e1d0e920d6cf4bdebe97e23523c5850e","9c0c907ab5604086803e0b95cbcd4dab","25a12769132140de9428badc5ec39f20","e8a9d59d48e84d7996b8d720f4aaef30","4e816b310126416aaad98a8da185c8da","1407c94b0ac44f5e93473ee46c994307","8ebcf6c8d1524a0bae821b43c6cb5d66","49b659a2a1bf4c419d5505d1304900fb","9659dcb541fa4942a1f4c12110bc6529","d421f38ebf7d462e8e60072deddfd5a8","a124a52176264facad1715b974c8df9c"]},"executionInfo":{"status":"ok","timestamp":1593150507172,"user_tz":-540,"elapsed":12799,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"f677d725-06b3-44f0-bec5-df8efbda1104"},"source":["model = ElectraForSequenceClassification.from_pretrained('google/electra-small-generator', num_labels=8)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b29d7158df5c4b4b863af9b5ccb2c4da","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=463.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8a9d59d48e84d7996b8d720f4aaef30","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=54236116.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=256, out_features=256, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=256, out_features=8, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"VXcncqM4Ghpl","colab_type":"code","colab":{}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, \n","                  eps = 1e-8\n","                )\n","\n","epochs = 30\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","# 학습률을 조금씩 감소시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ol_8ST0tHTJX","colab_type":"text"},"source":["## **학습**"]},{"cell_type":"code","metadata":{"id":"vgM7XAN8HVPK","colab_type":"code","colab":{}},"source":["from sklearn.metrics import f1_score\n","\n","# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","\n","def getF1Score(preds, labels):\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","\n","  return f1_score(labels_flat, pred_flat, average = None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-THBm2UHZJb","colab_type":"code","colab":{}},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Xnc1vL3HcHF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"aeb09343-7a2d-4fc6-865f-acb8d47e8a82"},"source":["seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","    total_loss = 0\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","             \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","\n","        loss = outputs[0]\n","        total_loss += loss.item()\n","\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","    model.eval()\n","    eval_loss, eval_accuracy, eval_f1 = 0, 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in dev_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        with torch.no_grad():     \n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        logits = outputs[0]\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","     \n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        # tmp_eval_f1 = getF1Score(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        # eval_f1 += tmp_eval_f1\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    # print(\"  F1: {0:.2f}\".format(eval_f1/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 30 ========\n","Training...\n","\n","  Average training loss: 1.48\n","  Training epcoh took: 0:00:32\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 30 ========\n","Training...\n","\n","  Average training loss: 1.26\n","  Training epcoh took: 0:00:32\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 3 / 30 ========\n","Training...\n","\n","  Average training loss: 1.16\n","  Training epcoh took: 0:00:32\n","\n","Running Validation...\n","  Accuracy: 0.56\n","  Validation took: 0:00:01\n","\n","======== Epoch 4 / 30 ========\n","Training...\n","\n","  Average training loss: 1.11\n","  Training epcoh took: 0:00:31\n","\n","Running Validation...\n","  Accuracy: 0.56\n","  Validation took: 0:00:01\n","\n","======== Epoch 5 / 30 ========\n","Training...\n","\n","  Average training loss: 1.06\n","  Training epcoh took: 0:00:31\n","\n","Running Validation...\n","  Accuracy: 0.56\n","  Validation took: 0:00:01\n","\n","======== Epoch 6 / 30 ========\n","Training...\n","\n","  Average training loss: 1.01\n","  Training epcoh took: 0:00:31\n","\n","Running Validation...\n","  Accuracy: 0.57\n","  Validation took: 0:00:01\n","\n","======== Epoch 7 / 30 ========\n","Training...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fyd_9TE3PSXR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1592204150014,"user_tz":-540,"elapsed":53601,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"e995d9ed-6f64-480a-b47d-ccf271487b9e"},"source":["tmp_test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=1)\n","test_result = test.copy(deep = True)\n","test_result = test_result.drop(columns = ['i_dialog', 'i_utterance', 'speaker'])\n","test_result['Predicted'] = 'default'\n","\n","encoder = LabelEncoder()\n","labels = train['emotion'].values\n","encoder.fit(labels)\n","labels = encoder.transform(labels)\n","\n","\n","for step, batch in enumerate(tmp_test_dataloader):\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_index, b_input_ids, b_input_mask = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    idx = b_index.item()\n","    test_result['Predicted'][idx] = encoder.classes_[np.argmax(logits)]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z34f7Gt_QO9E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1592202388355,"user_tz":-540,"elapsed":1015,"user":{"displayName":"­이지원[ 학부재학 / 컴퓨터학과 ]","photoUrl":"","userId":"04831763838828139292"}},"outputId":"e05393d5-6861-4386-9092-2f9ea237259d"},"source":["test_result.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>utterance</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3291</th>\n","      <td>3291</td>\n","      <td>I guess.</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3292</th>\n","      <td>3292</td>\n","      <td>So, shouldn?t we go give her the benefit of th...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3293</th>\n","      <td>3293</td>\n","      <td>Fine. I?m just glad I didn?t give her my secre...</td>\n","      <td>non-neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3294</th>\n","      <td>3294</td>\n","      <td>Out of curiosity, what is your secret ingredient?</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3295</th>\n","      <td>3295</td>\n","      <td>Yeah!</td>\n","      <td>joy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                          utterance    Predicted\n","3291  3291                                           I guess.      neutral\n","3292  3292  So, shouldn?t we go give her the benefit of th...      neutral\n","3293  3293  Fine. I?m just glad I didn?t give her my secre...  non-neutral\n","3294  3294  Out of curiosity, what is your secret ingredient?      neutral\n","3295  3295                                              Yeah!          joy"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"hSF-AK4URDAr","colab_type":"code","colab":{}},"source":["test_result = test_result.drop(columns = ['utterance'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2gejKanKVmn","colab_type":"code","colab":{}},"source":["test_csv = test_result.to_csv('sample.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L28Zvob-KgoQ","colab_type":"code","colab":{}},"source":["from google.colab import files\n","\n","files.download('sample.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDrBOhu1K-Eh","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}