{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20200806 KcBERT Large Fine Tune (NSMC) with GPU (Last update 2020.12.04)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "556c3fd23dfc400b8fd4f31cdb9d8f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f934453b1d004993ae084fffb53ceebf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5acba870af24ea8b380dd62e4fabf51",
              "IPY_MODEL_b8b302ce498543f3a50a5b7e858759fe"
            ]
          }
        },
        "f934453b1d004993ae084fffb53ceebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b5acba870af24ea8b380dd62e4fabf51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6622bc3b1704f84858b546c1dc9f496",
            "_dom_classes": [],
            "description": "Epoch 0:  16%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 12500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2029,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_431eb3ab1f5a4b6092d6f68b6bd28b75"
          }
        },
        "b8b302ce498543f3a50a5b7e858759fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_258137f69020405083d2e32439d62576",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2028/12500 [28:48&lt;2:28:46,  1.17it/s, loss=0.291, v_num=1]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b33a163103b408286ea6c636b089bcd"
          }
        },
        "e6622bc3b1704f84858b546c1dc9f496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "431eb3ab1f5a4b6092d6f68b6bd28b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258137f69020405083d2e32439d62576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b33a163103b408286ea6c636b089bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhpCIij5JHE7"
      },
      "source": [
        "Last Update @ 2020.12.04\n",
        "\n",
        "- Huggingface Transformers 4.0.0  버전 반영"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGAdyjAdF0kd"
      },
      "source": [
        "# Package 설치 & 데이터 받기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx2mHvhGFYBp"
      },
      "source": [
        "!pip install -q transformers pytorch_lightning emoji soynlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKK-Y9a3F6vr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341a144a-a5e5-42f9-e48c-d29596903e7d"
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nsmc' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYE7t_UNGiGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e0129f-82cb-4455-b547-8fad16841b78"
      },
      "source": [
        "!head nsmc/ratings_train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id\tdocument\tlabel\n",
            "9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n",
            "3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n",
            "10265843\t너무재밓었다그래서보는것을추천한다\t0\n",
            "9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n",
            "6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n",
            "5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n",
            "7797314\t원작의 긴장감을 제대로 살려내지못했다.\t0\n",
            "9443947\t별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네\t0\n",
            "7156791\t액션이 없는데도 재미 있는 몇안되는 영화\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLh_ziVCHwkH"
      },
      "source": [
        "# 패키지 import & 기본 Args 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb0113DUFE1k"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import re\n",
        "import emoji\n",
        "from soynlp.normalizer import repeat_normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN1zqYeKH2JZ"
      },
      "source": [
        "## 기본 학습 Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPr2_vTPFuP0"
      },
      "source": [
        "class Arg:\n",
        "    random_seed: int = 42  # Random Seed\n",
        "    pretrained_model: str = 'beomi/kcbert-large'  # Transformers PLM name\n",
        "    pretrained_tokenizer: str = ''  # Optional, Transformers Tokenizer Name. Overrides `pretrained_model`\n",
        "    auto_batch_size: str = 'power'  # Let PyTorch Lightening find the best batch size \n",
        "    batch_size: int = 0  # Optional, Train/Eval Batch Size. Overrides `auto_batch_size` \n",
        "    lr: float = 5e-6  # Starting Learning Rate\n",
        "    epochs: int = 20  # Max Epochs\n",
        "    max_length: int = 150  # Max Length input size\n",
        "    report_cycle: int = 100  # Report (Train Metrics) Cycle\n",
        "    train_data_path: str = \"nsmc/ratings_train.txt\"  # Train Dataset file \n",
        "    val_data_path: str = \"nsmc/ratings_test.txt\"  # Validation Dataset file \n",
        "    cpu_workers: int = os.cpu_count()  # Multi cpu workers\n",
        "    test_mode: bool = False  # Test Mode enables `fast_dev_run`\n",
        "    optimizer: str = 'AdamW'  # AdamW vs AdamP\n",
        "    lr_scheduler: str = 'exp'  # ExponentialLR vs CosineAnnealingWarmRestarts\n",
        "    fp16: bool = False  # Enable train on FP16\n",
        "    tpu_cores: int = 0  # Enable TPU with 1 core or 8 cores\n",
        "\n",
        "args = Arg()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmD2BQV9H8UQ"
      },
      "source": [
        "## 기본값을 Override 하고싶은 경우 아래와 같이 수정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w2Xgj8DI1-1",
        "outputId": "163009c2-ba20-4969-f761-19b26e62ace9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Dec  3 15:18:30 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biidCBmYI3FK"
      },
      "source": [
        "위에서 GPU가 V100/P100이면 아래 `batch_size`  를 32 이상으로 하셔도 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjwzybIrH70Y"
      },
      "source": [
        "# args.tpu_cores = 8  # Enables TPU\n",
        "args.fp16 = True  # Enables GPU FP16\n",
        "args.batch_size = 16  # Force setup batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2AcwMYa3nmd"
      },
      "source": [
        "# Model 만들기 with Pytorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImupuGXDGq7b"
      },
      "source": [
        "class Model(LightningModule):\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        self.args = options\n",
        "        self.bert = BertForSequenceClassification.from_pretrained(self.args.pretrained_model)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\n",
        "            self.args.pretrained_tokenizer\n",
        "            if self.args.pretrained_tokenizer\n",
        "            else self.args.pretrained_model\n",
        "        )\n",
        "\n",
        "    def forward(self, **kwargs):\n",
        "        return self.bert(**kwargs)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        data, labels = batch\n",
        "        output = self(input_ids=data, labels=labels)\n",
        "\n",
        "        # Transformers 4.0.0+\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "        \n",
        "        preds = logits.argmax(dim=-1)\n",
        "\n",
        "        y_true = labels.cpu().numpy()\n",
        "        y_pred = preds.cpu().numpy()\n",
        "\n",
        "        # Acc, Precision, Recall, F1\n",
        "        metrics = [\n",
        "            metric(y_true=y_true, y_pred=y_pred)\n",
        "            for metric in\n",
        "            (accuracy_score, precision_score, recall_score, f1_score)\n",
        "        ]\n",
        "\n",
        "        tensorboard_logs = {\n",
        "            'train_loss': loss.cpu().detach().numpy().tolist(),\n",
        "            'train_acc': metrics[0],\n",
        "            'train_precision': metrics[1],\n",
        "            'train_recall': metrics[2],\n",
        "            'train_f1': metrics[3],\n",
        "        }\n",
        "        if (batch_idx % self.args.report_cycle) == 0:\n",
        "            print()\n",
        "            pprint(tensorboard_logs)\n",
        "        return {'loss': loss, 'log': tensorboard_logs}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        data, labels = batch\n",
        "        output = self(input_ids=data, labels=labels)\n",
        "\n",
        "        # Transformers 4.0.0+\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "\n",
        "        preds = logits.argmax(dim=-1)\n",
        "\n",
        "        y_true = list(labels.cpu().numpy())\n",
        "        y_pred = list(preds.cpu().numpy())\n",
        "\n",
        "        return {\n",
        "            'loss': loss,\n",
        "            'y_true': y_true,\n",
        "            'y_pred': y_pred,\n",
        "        }\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        loss = torch.tensor(0, dtype=torch.float)\n",
        "        for i in outputs:\n",
        "            loss += i['loss'].cpu().detach()\n",
        "        _loss = loss / len(outputs)\n",
        "\n",
        "        loss = float(_loss)\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        for i in outputs:\n",
        "            y_true += i['y_true']\n",
        "            y_pred += i['y_pred']\n",
        "\n",
        "        # Acc, Precision, Recall, F1\n",
        "        metrics = [\n",
        "            metric(y_true=y_true, y_pred=y_pred)\n",
        "            for metric in\n",
        "            (accuracy_score, precision_score, recall_score, f1_score)\n",
        "        ]\n",
        "\n",
        "        tensorboard_logs = {\n",
        "            'val_loss': loss,\n",
        "            'val_acc': metrics[0],\n",
        "            'val_precision': metrics[1],\n",
        "            'val_recall': metrics[2],\n",
        "            'val_f1': metrics[3],\n",
        "        }\n",
        "\n",
        "        print()\n",
        "        pprint(tensorboard_logs)\n",
        "        return {'loss': _loss, 'log': tensorboard_logs}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        if self.args.optimizer == 'AdamW':\n",
        "            optimizer = AdamW(self.parameters(), lr=self.args.lr)\n",
        "        elif self.args.optimizer == 'AdamP':\n",
        "            from adamp import AdamP\n",
        "            optimizer = AdamP(self.parameters(), lr=self.args.lr)\n",
        "        else:\n",
        "            raise NotImplementedError('Only AdamW and AdamP is Supported!')\n",
        "        if self.args.lr_scheduler == 'cos':\n",
        "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n",
        "        elif self.args.lr_scheduler == 'exp':\n",
        "            scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
        "        else:\n",
        "            raise NotImplementedError('Only cos and exp lr scheduler is Supported!')\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'scheduler': scheduler,\n",
        "        }\n",
        "\n",
        "    def read_data(self, path):\n",
        "        if path.endswith('xlsx'):\n",
        "            return pd.read_excel(path)\n",
        "        elif path.endswith('csv'):\n",
        "            return pd.read_csv(path)\n",
        "        elif path.endswith('tsv') or path.endswith('txt'):\n",
        "            return pd.read_csv(path, sep='\\t')\n",
        "        else:\n",
        "            raise NotImplementedError('Only Excel(xlsx)/Csv/Tsv(txt) are Supported')\n",
        "\n",
        "    def preprocess_dataframe(self, df):\n",
        "        emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n",
        "        pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n",
        "        url_pattern = re.compile(\n",
        "            r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "\n",
        "        def clean(x):\n",
        "            x = pattern.sub(' ', x)\n",
        "            x = url_pattern.sub('', x)\n",
        "            x = x.strip()\n",
        "            x = repeat_normalize(x, num_repeats=2)\n",
        "            return x\n",
        "\n",
        "        df['document'] = df['document'].map(lambda x: self.tokenizer.encode(\n",
        "            clean(str(x)),\n",
        "            padding='max_length',\n",
        "            max_length=self.args.max_length,\n",
        "            truncation=True,\n",
        "        ))\n",
        "        return df\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        df = self.read_data(self.args.train_data_path)\n",
        "        df = self.preprocess_dataframe(df)\n",
        "\n",
        "        dataset = TensorDataset(\n",
        "            torch.tensor(df['document'].to_list(), dtype=torch.long),\n",
        "            torch.tensor(df['label'].to_list(), dtype=torch.long),\n",
        "        )\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.args.batch_size or self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.args.cpu_workers,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        df = self.read_data(self.args.val_data_path)\n",
        "        df = self.preprocess_dataframe(df)\n",
        "\n",
        "        dataset = TensorDataset(\n",
        "            torch.tensor(df['document'].to_list(), dtype=torch.long),\n",
        "            torch.tensor(df['label'].to_list(), dtype=torch.long),\n",
        "        )\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.args.batch_size or self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.args.cpu_workers,\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu1QkSZsHo8x"
      },
      "source": [
        "def main():\n",
        "    print(\"Using PyTorch Ver\", torch.__version__)\n",
        "    print(\"Fix Seed:\", args.random_seed)\n",
        "    seed_everything(args.random_seed)\n",
        "    model = Model(args)\n",
        "\n",
        "    print(\":: Start Training ::\")\n",
        "    trainer = Trainer(\n",
        "        max_epochs=args.epochs,\n",
        "        fast_dev_run=args.test_mode,\n",
        "        num_sanity_val_steps=None if args.test_mode else 0,\n",
        "        auto_scale_batch_size=args.auto_batch_size if args.auto_batch_size and not args.batch_size else False,\n",
        "        # For GPU Setup\n",
        "        deterministic=torch.cuda.is_available(),\n",
        "        gpus=-1 if torch.cuda.is_available() else None,\n",
        "        precision=16 if args.fp16 else 32,\n",
        "        # For TPU Setup\n",
        "        # tpu_cores=args.tpu_cores if args.tpu_cores else None,\n",
        "    )\n",
        "    trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBsvcdxySCqd"
      },
      "source": [
        "# 학습!\n",
        "\n",
        "> 주의: 1epoch별로 GPU-P100기준 약 2~3시간, GPU V100기준 ~40분이 걸립니다.\n",
        "\n",
        "> Update @ 2020.09.01\n",
        "> 최근 Colab Pro에서 V100이 배정됩니다.\n",
        "\n",
        "```python\n",
        "# 1epoch 기준 아래 score가 나옵니다.\n",
        "{'val_acc': 0.90522,\n",
        " 'val_f1': 0.9049023739289227,\n",
        " 'val_loss': 0.23429009318351746,\n",
        " 'val_precision': 0.9143146796431468,\n",
        " 'val_recall': 0.8956818813808446}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ewSOpY1Kwg6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "556c3fd23dfc400b8fd4f31cdb9d8f76",
            "f934453b1d004993ae084fffb53ceebf",
            "b5acba870af24ea8b380dd62e4fabf51",
            "b8b302ce498543f3a50a5b7e858759fe",
            "e6622bc3b1704f84858b546c1dc9f496",
            "431eb3ab1f5a4b6092d6f68b6bd28b75",
            "258137f69020405083d2e32439d62576",
            "5b33a163103b408286ea6c636b089bcd"
          ]
        },
        "outputId": "d085466d-abe4-4636-c158-e344acdc8efa"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch Ver 1.7.0+cu101\n",
            "Fix Seed: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-large were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ":: Start Training ::\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name | Type                          | Params\n",
            "-------------------------------------------------------\n",
            "0 | bert | BertForSequenceClassification | 334 M \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "556c3fd23dfc400b8fd4f31cdb9d8f76",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'train_acc': 0.625,\n",
            " 'train_f1': 0.7000000000000001,\n",
            " 'train_loss': 0.6730637550354004,\n",
            " 'train_precision': 0.875,\n",
            " 'train_recall': 0.5833333333333334}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
            "Please use self.log(...) inside the lightningModule instead.\n",
            "\n",
            "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
            "# (inside LightningModule)\n",
            "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'train_acc': 0.375,\n",
            " 'train_f1': 0.4444444444444444,\n",
            " 'train_loss': 0.6939505934715271,\n",
            " 'train_precision': 0.36363636363636365,\n",
            " 'train_recall': 0.5714285714285714}\n",
            "\n",
            "{'train_acc': 0.8125,\n",
            " 'train_f1': 0.8571428571428572,\n",
            " 'train_loss': 0.5000445246696472,\n",
            " 'train_precision': 0.9,\n",
            " 'train_recall': 0.8181818181818182}\n",
            "\n",
            "{'train_acc': 0.75,\n",
            " 'train_f1': 0.6666666666666666,\n",
            " 'train_loss': 0.41020798683166504,\n",
            " 'train_precision': 0.5714285714285714,\n",
            " 'train_recall': 0.8}\n",
            "\n",
            "{'train_acc': 0.9375,\n",
            " 'train_f1': 0.9090909090909091,\n",
            " 'train_loss': 0.188803568482399,\n",
            " 'train_precision': 0.8333333333333334,\n",
            " 'train_recall': 1.0}\n",
            "\n",
            "{'train_acc': 0.75,\n",
            " 'train_f1': 0.6666666666666666,\n",
            " 'train_loss': 0.4175763726234436,\n",
            " 'train_precision': 1.0,\n",
            " 'train_recall': 0.5}\n",
            "\n",
            "{'train_acc': 0.8125,\n",
            " 'train_f1': 0.823529411764706,\n",
            " 'train_loss': 0.3352031409740448,\n",
            " 'train_precision': 0.875,\n",
            " 'train_recall': 0.7777777777777778}\n",
            "\n",
            "{'train_acc': 0.875,\n",
            " 'train_f1': 0.9,\n",
            " 'train_loss': 0.3128831386566162,\n",
            " 'train_precision': 0.8181818181818182,\n",
            " 'train_recall': 1.0}\n",
            "\n",
            "{'train_acc': 0.875,\n",
            " 'train_f1': 0.8571428571428571,\n",
            " 'train_loss': 0.5296785831451416,\n",
            " 'train_precision': 1.0,\n",
            " 'train_recall': 0.75}\n",
            "\n",
            "{'train_acc': 0.8125,\n",
            " 'train_f1': 0.8,\n",
            " 'train_loss': 0.43987002968788147,\n",
            " 'train_precision': 1.0,\n",
            " 'train_recall': 0.6666666666666666}\n",
            "\n",
            "{'train_acc': 0.9375,\n",
            " 'train_f1': 0.923076923076923,\n",
            " 'train_loss': 0.36996957659721375,\n",
            " 'train_precision': 0.8571428571428571,\n",
            " 'train_recall': 1.0}\n",
            "\n",
            "{'train_acc': 0.75,\n",
            " 'train_f1': 0.8181818181818182,\n",
            " 'train_loss': 0.3643082082271576,\n",
            " 'train_precision': 0.8181818181818182,\n",
            " 'train_recall': 0.8181818181818182}\n",
            "\n",
            "{'train_acc': 1.0,\n",
            " 'train_f1': 1.0,\n",
            " 'train_loss': 0.11179850250482559,\n",
            " 'train_precision': 1.0,\n",
            " 'train_recall': 1.0}\n",
            "\n",
            "{'train_acc': 0.9375,\n",
            " 'train_f1': 0.888888888888889,\n",
            " 'train_loss': 0.1926622837781906,\n",
            " 'train_precision': 1.0,\n",
            " 'train_recall': 0.8}\n",
            "\n",
            "{'train_acc': 0.9375,\n",
            " 'train_f1': 0.9333333333333333,\n",
            " 'train_loss': 0.22411979734897614,\n",
            " 'train_precision': 0.875,\n",
            " 'train_recall': 1.0}\n",
            "\n",
            "{'train_acc': 0.75,\n",
            " 'train_f1': 0.75,\n",
            " 'train_loss': 0.4139561951160431,\n",
            " 'train_precision': 0.6666666666666666,\n",
            " 'train_recall': 0.8571428571428571}\n",
            "\n",
            "{'train_acc': 0.9375,\n",
            " 'train_f1': 0.9090909090909091,\n",
            " 'train_loss': 0.13431067764759064,\n",
            " 'train_precision': 0.8333333333333334,\n",
            " 'train_recall': 1.0}\n",
            "\n",
            "{'train_acc': 0.8125,\n",
            " 'train_f1': 0.7692307692307693,\n",
            " 'train_loss': 0.31965121626853943,\n",
            " 'train_precision': 1.0,\n",
            " 'train_recall': 0.625}\n",
            "\n",
            "{'train_acc': 0.9375,\n",
            " 'train_f1': 0.9333333333333333,\n",
            " 'train_loss': 0.18948166072368622,\n",
            " 'train_precision': 1.0,\n",
            " 'train_recall': 0.875}\n",
            "\n",
            "{'train_acc': 0.75,\n",
            " 'train_f1': 0.75,\n",
            " 'train_loss': 0.5539512038230896,\n",
            " 'train_precision': 0.75,\n",
            " 'train_recall': 0.75}\n",
            "\n",
            "{'train_acc': 0.6875,\n",
            " 'train_f1': 0.6666666666666666,\n",
            " 'train_loss': 0.3646361827850342,\n",
            " 'train_precision': 0.7142857142857143,\n",
            " 'train_recall': 0.625}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqYPE5ObKxZp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}